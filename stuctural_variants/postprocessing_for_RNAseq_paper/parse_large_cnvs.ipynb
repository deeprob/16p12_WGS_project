{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv('../16p12.2_rnaseq_analysis/data/pheno_final.tsv', sep='\\t')\n",
    "\n",
    "pheno = pheno.drop_duplicates('subject')\n",
    "samples = list(pheno.subject.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_codes.list', 'r') as f:\n",
    "    allsamples = f.readlines()\n",
    "allsamples = [s.strip() for s in allsamples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PennCNV: combine 16p and second hit variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 20)\n",
      "(660, 20)\n"
     ]
    }
   ],
   "source": [
    "df_16p = pd.read_csv('PennCNV_16p.csv')\n",
    "df_rest = pd.read_csv('PennCNV_rare_second_hit.csv')\n",
    "\n",
    "print(df_16p.shape)\n",
    "print(df_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_16p.append(df_rest).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/penncnv/PennCNV_full.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNVnator: filter > 50kbp and merge nearby calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end(s):\n",
    "    l = s.split(';')\n",
    "    s = 'END=0'\n",
    "    for item in l:\n",
    "        if item.startswith('END='):\n",
    "            s = item\n",
    "    s = s.split('=')[1]\n",
    "    if s.startswith('-'):\n",
    "        s = s[1:]\n",
    "    return int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caller='cnvnator_large'\n",
    "columns = ['chrom','pos','id','ref','alt','qual','filter','info','format','sample']\n",
    "\n",
    "for sample in allsamples[:]:\n",
    "#     print(sample)\n",
    "\n",
    "    filepath = '/data5/16p12_WGS/structural_variants/vcf_callers/output/cnvnator/bin200/cnv2vcf.{}.cnvnator.vcf'\n",
    "    df = pd.read_csv(filepath.format(sample), \n",
    "                     sep='\\t', comment='#', header=None, names=columns)\n",
    "\n",
    "    df['start'] = df['pos']\n",
    "    df['end'] = df['info'].apply(lambda s: get_end(s))\n",
    "    df['svlength'] = df['end'] - df['start']\n",
    "    df['svtype'] = df.alt.apply(lambda s: s.strip('<').strip('>'))\n",
    "    \n",
    "    df = df[df.svlength > 50e3]\n",
    "    \n",
    "    new_entries = []\n",
    "    \n",
    "    for chrom in list(df.chrom.unique())[:]:\n",
    "        dfc = df[df.chrom == chrom]\n",
    "        for sv in list(df.svtype.unique()):\n",
    "#             print(chrom, sv)\n",
    "            dfcs = dfc[dfc.svtype == sv]\n",
    "            if dfcs.shape[0] == 0:\n",
    "                continue\n",
    "            p_i = dfcs.index[0]\n",
    "\n",
    "            p_row = dfcs.loc[p_i]\n",
    "            p_start = p_row['start']\n",
    "            p_end = p_row['end']\n",
    "            p_length = p_row['svlength']\n",
    "            p_svtype = p_row['svtype']\n",
    "\n",
    "            for i in dfcs.index[1:]:\n",
    "                row = dfcs.loc[i]\n",
    "                start = row['start']\n",
    "                end = row['end']\n",
    "                length = row['svlength']\n",
    "                svtype = row['svtype']\n",
    "\n",
    "                gap = start - p_end\n",
    "                if (gap < 50e3) & (gap < .2 *max(length, p_length)) & (p_svtype == svtype):\n",
    "                    p_end = end\n",
    "                    p_length = p_end-p_start\n",
    "                new_entries.append([chrom, p_start, p_end, p_svtype])\n",
    "                p_start, p_end, p_length, p_svtype = start, end, length, svtype\n",
    "    df_new = pd.DataFrame(new_entries, columns = ['chrom', 'start', 'end', 'svtype'])\n",
    "    df_new['length'] = df_new.end - df_new.start\n",
    "    \n",
    "    \n",
    "    df_new.to_csv('output/{}/{}.{}.tsv'.format(caller, sample, caller), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNVnator: get Intra-cohort Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['chrom', 'start', 'end', 'svtype', 'svlength']\n",
    "dfall = pd.DataFrame(columns = cols)\n",
    "\n",
    "for subject in allsamples:\n",
    "    dfa = pd.read_csv('output/cnvnator_large/{}.cnvnator_large.tsv'.format(subject), \n",
    "                 sep='\\t')\n",
    "    dfa.columns = cols\n",
    "    dfa['subject'] = subject\n",
    "    dfall = dfall.append(dfa)\n",
    "    \n",
    "dfall = dfall.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in allsamples:\n",
    "#     print(subject)\n",
    "    df = dfall[dfall.subject == subject].copy()\n",
    "    rdf = dfall[dfall.subject != subject]\n",
    "    \n",
    "    df['intra_cohort_count'] = 0\n",
    "\n",
    "    for chrom in df.chrom.unique()[:]:\n",
    "        for svtype in ['DUP', 'DEL']:\n",
    "            dfc = df[(df.chrom == chrom) & (df.svtype == svtype)]\n",
    "            rdfc = rdf[(rdf.chrom == chrom) & (rdf.svtype == svtype)]\n",
    "\n",
    "            for i in dfc.index[:]:\n",
    "                start = dfc.at[i, 'start']\n",
    "                end = dfc.at[i, 'end']\n",
    "                length = dfc.at[i, 'svlength']\n",
    "                min_end   = rdfc.end.apply(lambda x: min(x, end))\n",
    "                max_start = rdfc.start.apply(lambda x: max(x, start))\n",
    "                max_length = rdfc.svlength.apply(lambda x: max(x, length))\n",
    "                odf = rdfc[(min_end - max_start) > .5 * max_length]\n",
    "\n",
    "                if odf.shape[0] > 0:\n",
    "                    count = len(odf.subject.unique())\n",
    "                    df.at[i, 'intra_cohort_count'] = count\n",
    "\n",
    "    df['intra_cohort_freq'] = df['intra_cohort_count']/ 345.\n",
    "    df.to_csv('output/cnvnator_large/{}.intra_cohort.tsv'.format(subject), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNVnator: filter <10 count and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('output/cnvnator_large/{}.intra_cohort.tsv'.format(subject), sep='\\t').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['chrom', 'start', 'end', 'svtype', 'svlength', 'subject',\n",
    "       'intra_cohort_count', 'intra_cohort_freq']\n",
    "dfall = pd.DataFrame(columns = cols)\n",
    "\n",
    "for subject in allsamples:\n",
    "    dfa = pd.read_csv('output/cnvnator_large/{}.intra_cohort.tsv'.format(subject), sep='\\t')\n",
    "    dfa.columns = cols\n",
    "    dfa['subject'] = subject\n",
    "    dfall = dfall.append(dfa)\n",
    "    \n",
    "dfall = dfall.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = dfall[dfall.intra_cohort_count < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.to_csv('output/cnvnator_large/cnvnator.filtered_intra.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine cnvnator and PennCNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nator = pd.read_csv('output/cnvnator_large/cnvnator.filtered_intra.tsv', sep='\\t')\n",
    "penn  = pd.read_csv('output/penncnv/PennCNV_full.tsv', sep='\\t')\n",
    "\n",
    "nator = nator[['chrom', 'start', 'end', 'svtype', 'subject', 'svlength']].copy()\n",
    "nator.columns = ['chrom', 'start', 'end', 'svtype', 'subject', 'length']\n",
    "\n",
    "nator['caller'] = 'cnvnator'\n",
    "\n",
    "penn = penn[['Chromosome', 'Start', 'End', 'CNV_type', 'Patient_ID']].copy()\n",
    "penn['length'] = penn.End - penn.Start\n",
    "penn.columns = ['chrom', 'start', 'end', 'svtype', 'subject', 'length']\n",
    "penn['caller'] = 'pennCNV'\n",
    "penn.svtype = penn.svtype.apply(lambda s: s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = []\n",
    "\n",
    "for subject in allsamples:\n",
    "#     print(subject)\n",
    "    snator = nator[nator.subject == subject].copy()\n",
    "    spenn = penn[penn.subject == subject].copy()\n",
    "    \n",
    "    chromosomes = list(set(snator.chrom.to_list() + spenn.chrom.to_list()))\n",
    "#     print(chromosomes)\n",
    "    for chrom in chromosomes:\n",
    "        for svtype in ['DUP', 'DEL']:\n",
    "            snatord = snator[(snator.svtype == svtype) & (snator.chrom == chrom)]\n",
    "            spennd = spenn[(spenn.svtype == svtype) & (spenn.chrom == chrom)]\n",
    "            \n",
    "            dfd = pd.concat([snatord, spennd])\n",
    "            if dfd.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            dfd = dfd.sort_values(['start', 'caller'] )\n",
    "            dfd = dfd.reset_index(drop=True)\n",
    "\n",
    "            done_i_list = []\n",
    "\n",
    "            for i in dfd.index[:]:\n",
    "\n",
    "                if i in done_i_list:\n",
    "                    continue\n",
    "                start = dfd.at[i, 'start']\n",
    "                end = dfd.at[i, 'end']\n",
    "                length = dfd.at[i, 'length']\n",
    "                caller = dfd.at[i, 'caller']\n",
    "#                 print(i, start, end , length, caller)\n",
    "\n",
    "                min_end    = dfd['end'].apply(lambda x: min(x, end))\n",
    "                max_start  = dfd['start'].apply(lambda x: max(x, start))\n",
    "                max_length = dfd['length'].apply(lambda x: max(x, length))\n",
    "                overlap    = (min_end - max_start) > .5 * max_length\n",
    "\n",
    "                if dfd[(overlap) & (dfd.caller != caller)].shape[0] > 0:\n",
    "                    odf = dfd[(overlap)]\n",
    "                    keep.append([chrom, odf['start'].min(), odf['end'].max(), subject, svtype, ','.join(odf.caller.unique()), len(odf.caller.unique())])\n",
    "\n",
    "\n",
    "                    done_i_list = done_i_list + list(odf.index)\n",
    "                else:\n",
    "                    odf = dfd[(overlap)]\n",
    "                    keep.append([chrom, odf['start'].min(), odf['end'].max(), subject, svtype, ','.join(odf.caller.unique()), len(odf.caller.unique())])\n",
    "\n",
    "                    done_i_list.append(i)\n",
    "                    \n",
    "keep = pd.DataFrame(keep)\n",
    "keep.columns = ['chrom', 'start', 'end', 'subject', 'svtype', 'caller', 'num_callers']\n",
    "keep['length'] = keep['end'] - keep['start']\n",
    "keep = keep.sort_values(['chrom', 'start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep.to_csv('output/merged_greater_50/merged.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gene annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output/merged_greater_50/merged.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.read_csv('refGene_hg19.txt', sep='\\t', header=None)\n",
    "\n",
    "gdf['chrom'] = gdf[2]\n",
    "gdf['start'] = gdf[4]\n",
    "gdf['end']   = gdf[5]\n",
    "gdf['gene']  = gdf[12]\n",
    "gdf = gdf[['chrom', 'start', 'end', 'gene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genes'] = ''\n",
    "\n",
    "for chrom in df.chrom.unique():\n",
    "#     print(chrom)\n",
    "    dfc = df[df.chrom == chrom]\n",
    "    gdfc = gdf[gdf.chrom == chrom]\n",
    "    for i in dfc.index[:]:\n",
    "        start = dfc.at[i, 'start']\n",
    "        end = dfc.at[i, 'end']\n",
    "        min_end   = gdfc.end.apply(lambda x: min(x, end))\n",
    "        max_start = gdfc.start.apply(lambda x: max(x, start))\n",
    "        odf = gdfc[(min_end - max_start) > 0]\n",
    "        if odf.shape[0] > 0:\n",
    "            df.at[i, 'genes'] = ';'.join(odf.gene.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/merged_greater_50/merged.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
